{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55935f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 머신러닝 모델에 대하여 성능 평가가 가능함\n",
    "from model_test import Model_Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90115930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 객체\n",
    "class Model_Evaluation():\n",
    "\n",
    "    def __init__(self, result, call_model):\n",
    "        self.catboost_model = call_model # 평가할 모델 호출\n",
    "        print(f'훈련용 평가지표: {self.catboost_model.score(result.train_final, result.y_train)} / 테스트용 평가지표: {self.catboost_model.score(result.test_final, result.y_test)}')\n",
    "\n",
    "        # test.csv에 대한 성능평가\n",
    "        print(f'test.csv 평가지표: {self.catboost_model.score(result.test_df_final, result.test_df_y)}')\n",
    "        # train.csv에 대한 roc_curve\n",
    "        print(f\"train.csv에 대한 로컬PC Score: {self.do_roc_curve(self.catboost_model, result.test_final, result.y_test)}\")\n",
    "        # test.csv에 대한 roc_curve\n",
    "        print(f\"test.csv에 대한 로컬PC Score: {self.do_roc_curve(self.catboost_model, result.test_df_final, result.test_df_y)}\")\n",
    "\n",
    "        # train.csv에 대한 confusion matrix\n",
    "        print(\"=\" * 30)\n",
    "        print(\"train.csv confusion matrix\")\n",
    "        print(self.do_confusion_matrix(self.catboost_model, result.test_final, result.y_test))\n",
    "\n",
    "        # test.csv에 대한 confusion matrix\n",
    "        print(\"=\" * 30)\n",
    "        print(\"test.csv confusion matrix\")\n",
    "        print(self.do_confusion_matrix(self.catboost_model, result.test_df_final, result.test_df_y))\n",
    "\n",
    "        # 훈련 데이터 f1 evaluation 결과\n",
    "        self.val_acc, self.val_f1, self.val_report = self.get_f1_evaluation(self.catboost_model, result.test_final, result.y_test)\n",
    "        print(\"=\" * 30)\n",
    "        print(\"validation Accuracy:\", self.val_acc)\n",
    "        print(\"validation Macro-F1:\", self.val_f1)\n",
    "        print(self.val_report)\n",
    "\n",
    "        # 테스트 데이터 f1 evaluation 결과\n",
    "        self.val_acc, self.val_f1, self.val_report = self.get_f1_evaluation(self.catboost_model, result.test_df_final, result.test_df_y)\n",
    "        print(\"=\" * 30)\n",
    "        print(\"validation Accuracy:\", self.val_acc)\n",
    "        print(\"validation Macro-F1:\", self.val_f1)\n",
    "        print(self.val_report)\n",
    "    \n",
    "    # train.csv에 대한 roc_curve\n",
    "    def do_roc_curve(self, model, test, predict):\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "        self.y_predict = model.predict(test)\n",
    "        self.fpr, self.tpr, self.thresholds = roc_curve(predict, self.y_predict)\n",
    "\n",
    "        self.score_auc = auc(self.fpr, self.tpr)\n",
    "\n",
    "        return self.score_auc\n",
    "    \n",
    "    # confusion matrix\n",
    "    def do_confusion_matrix(self, model, test_final, y_test):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        self.pred_tree = model.predict(test_final)\n",
    "        self.conf_mx = confusion_matrix(y_test, self.pred_tree, normalize='true')\n",
    "\n",
    "        return self.conf_mx\n",
    "    \n",
    "    # f1-score 지수 평가\n",
    "    def get_f1_evaluation(self, model, df_final, y_final):\n",
    "        from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "        # 훈련 데이터 평가\n",
    "        self.y_pred = model.predict(df_final)\n",
    "        self.val_acc = accuracy_score(y_final, self.y_pred)\n",
    "        self.val_f1 = f1_score(y_final, self.y_pred, average=\"macro\")\n",
    "        self.val_report = classification_report(y_final, self.y_pred)\n",
    "\n",
    "        return self.val_acc, self.val_f1, self.val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa01534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 객체\n",
    "class Catboost():\n",
    "\n",
    "    def CallCatboost(result):\n",
    "        from catboost import CatBoostClassifier\n",
    "\n",
    "        model = CatBoostClassifier(verbose=False, random_state=result.SEED)\n",
    "        model.fit(result.train_final, result.y_train)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58c91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda import DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2544349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost>\n",
      "훈련용 평가지표: 1.0 / 테스트용 평가지표: 0.9928571428571429\n",
      "test.csv 평가지표: 0.9953333333333333\n",
      "train.csv에 대한 로컬PC Score: 0.9928650731452455\n",
      "test.csv에 대한 로컬PC Score: 0.9953580901856764\n",
      "==============================\n",
      "train.csv confusion matrix\n",
      "[[0.99425287 0.00574713]\n",
      " [0.00852273 0.99147727]]\n",
      "==============================\n",
      "test.csv confusion matrix\n",
      "[[1.         0.        ]\n",
      " [0.00928382 0.99071618]]\n",
      "==============================\n",
      "validation Accuracy: 0.9928571428571429\n",
      "validation Macro-F1: 0.9928570116593978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       348\n",
      "           1       0.99      0.99      0.99       352\n",
      "\n",
      "    accuracy                           0.99       700\n",
      "   macro avg       0.99      0.99      0.99       700\n",
      "weighted avg       0.99      0.99      0.99       700\n",
      "\n",
      "==============================\n",
      "validation Accuracy: 0.9953333333333333\n",
      "validation Macro-F1: 0.9953333312592583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       746\n",
      "           1       1.00      0.99      1.00       754\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model_Evaluation at 0x2042989d010>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = DataProcessing(\"./data/train.csv\", \"./data/test.csv\")\n",
    "call_model = Catboost.CallCatboost(result) # 평가할 모델 설정\n",
    "print(\"<catboost>\")\n",
    "Model_Evaluation(result, call_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55641655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "\n",
    "    def CallRandomForest(result):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        model_rf = RandomForestClassifier(random_state=result.SEED)\n",
    "        model_rf = model_rf.fit(result.train_final, result.y_train)\n",
    "\n",
    "        return model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df26d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RandomForest>\n",
      "훈련용 평가지표: 1.0 / 테스트용 평가지표: 0.9714285714285714\n",
      "test.csv 평가지표: 0.9753333333333334\n",
      "train.csv에 대한 로컬PC Score: 0.9714276384535006\n",
      "test.csv에 대한 로컬PC Score: 0.9753290760270514\n",
      "==============================\n",
      "train.csv confusion matrix\n",
      "[[0.97126437 0.02873563]\n",
      " [0.02840909 0.97159091]]\n",
      "==============================\n",
      "test.csv confusion matrix\n",
      "[[0.97453083 0.02546917]\n",
      " [0.02387268 0.97612732]]\n",
      "==============================\n",
      "validation Accuracy: 0.9714285714285714\n",
      "validation Macro-F1: 0.9714276384535006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       348\n",
      "           1       0.97      0.97      0.97       352\n",
      "\n",
      "    accuracy                           0.97       700\n",
      "   macro avg       0.97      0.97      0.97       700\n",
      "weighted avg       0.97      0.97      0.97       700\n",
      "\n",
      "==============================\n",
      "validation Accuracy: 0.9753333333333334\n",
      "validation Macro-F1: 0.9753324453013642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       746\n",
      "           1       0.97      0.98      0.98       754\n",
      "\n",
      "    accuracy                           0.98      1500\n",
      "   macro avg       0.98      0.98      0.98      1500\n",
      "weighted avg       0.98      0.98      0.98      1500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model_Evaluation at 0x2042ae53c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"<RandomForest>\")\n",
    "Model_Evaluation(result, RandomForest.CallRandomForest(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eeb95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost():\n",
    "\n",
    "    def CallXGBoost(result):\n",
    "        from xgboost import XGBClassifier\n",
    "\n",
    "        model_xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        random_state=result.SEED,\n",
    "        n_jobs=-1\n",
    "        )\n",
    "        model_xgb = model_xgb.fit(result.train_final, result.y_train)\n",
    "\n",
    "        return model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e45706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<XGBoost>\n",
      "훈련용 평가지표: 1.0 / 테스트용 평가지표: 0.99\n",
      "test.csv 평가지표: 0.9913333333333333\n",
      "train.csv에 대한 로컬PC Score: 0.9899751828631138\n",
      "test.csv에 대한 로컬PC Score: 0.9913366424644967\n",
      "==============================\n",
      "train.csv confusion matrix\n",
      "[[0.98563218 0.01436782]\n",
      " [0.00568182 0.99431818]]\n",
      "==============================\n",
      "test.csv confusion matrix\n",
      "[[0.9919571  0.0080429 ]\n",
      " [0.00928382 0.99071618]]\n",
      "==============================\n",
      "validation Accuracy: 0.99\n",
      "validation Macro-F1: 0.9899989998999901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       348\n",
      "           1       0.99      0.99      0.99       352\n",
      "\n",
      "    accuracy                           0.99       700\n",
      "   macro avg       0.99      0.99      0.99       700\n",
      "weighted avg       0.99      0.99      0.99       700\n",
      "\n",
      "==============================\n",
      "validation Accuracy: 0.9913333333333333\n",
      "validation Macro-F1: 0.9913331445884821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       746\n",
      "           1       0.99      0.99      0.99       754\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model_Evaluation at 0x20429883c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"<XGBoost>\")\n",
    "Model_Evaluation(result, XGBoost.CallXGBoost(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1745b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBM():\n",
    "\n",
    "    def CallLightGBM(result):\n",
    "        import lightgbm as lgb\n",
    "\n",
    "        model_lgbm = lgb.LGBMClassifier(random_state=result.SEED)\n",
    "        model_lgbm.fit(result.train_final, result.y_train)\n",
    "\n",
    "        return model_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32785e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LightGBM>\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1409, number of negative: 1391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 723\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503214 -> initscore=0.012857\n",
      "[LightGBM] [Info] Start training from score 0.012857\n",
      "훈련용 평가지표: 1.0 / 테스트용 평가지표: 0.9871428571428571\n",
      "test.csv 평가지표: 0.9886666666666667\n",
      "train.csv에 대한 로컬PC Score: 0.9871016196447231\n",
      "test.csv에 대한 로컬PC Score: 0.9886841225705976\n",
      "==============================\n",
      "train.csv confusion matrix\n",
      "[[0.97988506 0.02011494]\n",
      " [0.00568182 0.99431818]]\n",
      "==============================\n",
      "test.csv confusion matrix\n",
      "[[0.9919571  0.0080429 ]\n",
      " [0.01458886 0.98541114]]\n",
      "==============================\n",
      "validation Accuracy: 0.9871428571428571\n",
      "validation Macro-F1: 0.9871407314270318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       348\n",
      "           1       0.98      0.99      0.99       352\n",
      "\n",
      "    accuracy                           0.99       700\n",
      "   macro avg       0.99      0.99      0.99       700\n",
      "weighted avg       0.99      0.99      0.99       700\n",
      "\n",
      "==============================\n",
      "validation Accuracy: 0.9886666666666667\n",
      "validation Macro-F1: 0.9886666213331521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       746\n",
      "           1       0.99      0.99      0.99       754\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model_Evaluation at 0x2042c632780>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"<LightGBM>\")\n",
    "Model_Evaluation(result, LightGBM.CallLightGBM(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e467c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
